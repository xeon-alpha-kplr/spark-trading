from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, DoubleType
import time
import requests

# Créer une session Spark
spark = SparkSession.builder.appName("AlphaVantageStreaming").getOrCreate()

# Définir le schéma des données
schema = StructType([
    StructField("from_currency_code", StringType(), True),
    StructField("to_currency_code", StringType(), True),
    StructField("exchange_rate", DoubleType(), True),
    StructField("last_refreshed", StringType(), True),
    StructField("timezone", StringType(), True),
])

# Fonction pour récupérer les données de taux de change depuis Alpha Vantage
def fetch_currency_exchange_data():
    # Remplacer 'YOUR_API_KEY' par votre propre clé d'API Alpha Vantage
    api_key = 'YOUR_API_KEY'
    from_currency = 'EUR'  # Devise de départ
    to_currency = 'USD'  # Devise de destination

    # Faire une requête à l'API pour obtenir les données
    response = requests.get(f'https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency={from_currency}&to_currency={to_currency}&apikey={api_key}')
    data = response.json()['Realtime Currency Exchange Rate']

    # Créer une liste de tuples avec les données de taux de change
    rows = [(data['1. From_Currency Code'], data['3. To_Currency Code'], float(data['5. Exchange Rate']), data['6. Last Refreshed'], data['7. Time Zone'])]

    return rows

# Boucle de récupération périodique des données
while True:
    # Récupérer les données de taux de change
    rows = fetch_currency_exchange_data()

    # Convertir les données en DataFrame Spark
    data = spark.createDataFrame(rows, schema)

    # Afficher les données
    data.show()

    # Attendre pendant un certain intervalle avant la prochaine récupération
    time.sleep(15)  # Par exemple, attendre 60 secondes (1 minute) entre chaque récupération
